{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NavScript",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/hdh7485/cnn-text-classification-tf/blob/master/NavScript.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "RUymE2l9GZfO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "JMyTNwSJGGWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_u-x-nI5EOXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "21878c6a-6306-4ef7-a2e1-681fef1c2402"
      },
      "cell_type": "code",
      "source": [
        "!ps ax|grep python"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   89 ?        Sl     0:01 /usr/bin/python2 /usr/local/bin/jupyter-notebook -y --no-browser --log-level=DEBUG --debug --NotebookApp.allow_origin=\"*\" --NotebookApp.log_format=\"%(message)s\" --NotebookApp.token= --Session.key=\"\" --Session.keyfile=\"\" --ContentsManager.untitled_directory=\"Untitled Folder\" --ContentsManager.untitled_file=\"Untitled File\" --ContentsManager.untitled_notebook=\"Untitled Notebook\" --NotebookNotary.algorithm=\"sha1\" --KernelManager.autorestart=True --MultiKernelManager.default_kernel_name=\"python2\" --ip=\"127.0.0.1\" --port=9000 --port-retries=0 --notebook-dir=\"/content\" --NotebookNotary.algorithm=sha256 --NotebookNotary.secret_file=/content/datalab/.config/notary_secret --NotebookApp.base_url=/tun/m/gpu-cc67aecd-ee17-4bb8-8158-8ded892e6622/\r\n",
            "   97 ?        Ssl    1:16 /usr/bin/python3 -m ipykernel_launcher -f /content/.local/share/jupyter/runtime/kernel-b880ed7c-d88e-415c-a2f8-571629d14dce.json\r\n",
            "  875 pts/0    Ss+    0:01 /bin/sh -c ps ax|grep python\r\n",
            "  877 pts/0    S+     0:00 grep python\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "__UZ7CnAedEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a945b6cb-4938-4b31-ff21-bebb3110789f"
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwnnSLU9eTxe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "37f32956-f7ca-4ee9-f6c5-e9396733f338"
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 11.1 GB  I Proc size: 2.0 GB\n",
            "GPU RAM Free: 548MB | Used: 10891MB | Util  95% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "co7MV6sX7Xto",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Universal Sentence Encoder\n",
        "\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td></table>\n"
      ]
    },
    {
      "metadata": {
        "id": "eAVQGidpL8v5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
        "\n",
        "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
      ]
    },
    {
      "metadata": {
        "id": "pOTzp8O36CyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "\n",
        "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
      ]
    },
    {
      "metadata": {
        "id": "lVjNK8shFKOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfe43e3f-d317-4b29-d512-f7d82561decd"
      },
      "cell_type": "code",
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install seaborn"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.7.1)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "63Pd3nJnTl-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
      ]
    },
    {
      "metadata": {
        "id": "MSeY-MUQo2Ha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6j1I5msVLY3N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rmse(predictions, targets):\n",
        "  return np.sqrt(((predictions - targets)**2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwty8Z6mAkdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 미리 학습된 모듈의 url\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/1\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/1\", \"https://tfhub.dev/google/universal-sentence-encoder-large/1\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIGQxCZSsr-a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scripts = [\"[SEARCH FROM:WEATHERFORECAST WHERE:HERE WHEN:AFTERNOON]\",\n",
        "         \"[SEARCH FROM:TRAFFIC WHERE:ONROUTE]\",\n",
        "         \"[SEARCH FROM:TRAFFICCAMERA WHERE:[SEARCH GEOCODE WHERE:”US-101 and Bayshore Blvd”]]\",\n",
        "         \"[SEARCH FROM:GASSTATION WHERE:NEARBY WITH:RESTROOM]\",\n",
        "         \"[SEARCH ONE FROM:COFFEESHOP WHERE:ALONGROUTE]\",\n",
        "         \"[SEARCH ONE FROM:OFFROADPARKING WHERE:DESTINATION RANGE:500M WITH:[SORT PRICE ASC]]\",\n",
        "         \"[SEARCH ONE FROM:SUPERMARKET WHERE:ONROUTE WITH:CHARGINGSTATION]\",\n",
        "         \"[SEARCH ONE FROM:PARKING WITH:CREDITCARD WITH:VALETSERVICE]\",\n",
        "         \"[ROUTE TO:[SEARCH KEYWORD:”San Francisco Museum of Modern Art”]]\",\n",
        "         \"[ROUTE INFO:ETA]\",\n",
        "         \"[ROUTE ALTROUTE]\",\n",
        "         \"[ROUTE ALTROUTE USE:[SEARCH LINKS:ROUTE]]\",\n",
        "         \"[MODE ROUTEOVERVIEW]\",\n",
        "         \"[MODE GUIDANCE WITH:[ROUTE TO:[SEARCH KEYWORD:”Downtown Berkeley”]]]\",\n",
        "         \"[MODE DRIVERANGE]\",\n",
        "         \"[MODE DRIVERANGE TO:[SEARCH KEYWORD:”10AM MEETING” FROM:SCHEDULE WHEN:10AM] WITH:[VOICERESPONSE TEMPLATE:YES/NO*]]\",\n",
        "         \"[MODE TRAFFIC [SEARCH FROM:TRAFFIC WHERE:[SEARCH KEYWORD:”Bay Bridge”]] WITH:[VOICERESPONSE TEMPLATE:””*]\",\n",
        "         \"[MODE SPEEDCAMERA WHERE:ONROUTE WITH:[VOICERESPONSE TEMPLATE:””*]]\",\n",
        "         \"[MODE WEATHERFORECAST WHERE:[SEARCH KEYWORD:”Oakland”] WHEN:TOMORROW]\"\n",
        "          ]\n",
        "\n",
        "# Compute a representation for each message, showing various lengths supported.\n",
        "messages = [\"What's the something for this time?\",\n",
        "            \"What's the something like on place?\",\n",
        "            \"Show me a something on geocode and geocode.\",\n",
        "            \"Can you find me a something with something where?\",\n",
        "            \"Find a something where.\",\n",
        "            \"Find the cheapest indoor parking within 500 meters of my destination.\",\n",
        "            \"Okay, can you find me a supermarket on my route that has a charging station?\",\n",
        "            \"Find parking near destination that accepts credit cards and has a valet service.\",\n",
        "            \"Navigate to San Francisco Museum of Modern Art.\",\n",
        "            \"What's my ETA to destination?\",\n",
        "            \"Show me alternative routes.\",\n",
        "            \"Reroute using I-580 East.\",\n",
        "            \"Show route overview.\",\n",
        "            \"Drive to Downtown Berkeley.\",\n",
        "            \"What's my drive range?\",\n",
        "            \"Can I make tomorrow's 10am meeting without recharging?\",\n",
        "            \"What's traffic like on the Bay Bridge?\",\n",
        "            \"Are there any speed cameras on my route?\",\n",
        "            \"Will it rain tomorrow in Oakland?\"\n",
        "            ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8F4LNGFqOiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  #임베딩 시작\n",
        "  message_embeddings = session.run(embed(messages))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pzff6G4YH4jY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1347
        },
        "outputId": "3542782f-3edd-4029-c612-e0233c2078d3"
      },
      "cell_type": "code",
      "source": [
        "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "    print(\"Message: {}\".format(messages[i]))\n",
        "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
        "    message_embedding_snippet = \", \".join(\n",
        "        (str(x) for x in message_embedding[:3]))\n",
        "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message: What's the something for this time?\n",
            "Embedding size: 512\n",
            "Embedding: [0.10562784969806671, 0.007974918931722641, -0.05560705065727234, ...]\n",
            "\n",
            "Message: What's the something like on place?\n",
            "Embedding size: 512\n",
            "Embedding: [0.09381017833948135, 0.007413230370730162, -0.015313537791371346, ...]\n",
            "\n",
            "Message: Show me a something on geocode and geocode.\n",
            "Embedding size: 512\n",
            "Embedding: [0.09865029156208038, -0.03687693923711777, -0.017361536622047424, ...]\n",
            "\n",
            "Message: Can you find me a something with something where?\n",
            "Embedding size: 512\n",
            "Embedding: [0.09483873844146729, -0.019978588446974754, -0.05640304088592529, ...]\n",
            "\n",
            "Message: Find a something where.\n",
            "Embedding size: 512\n",
            "Embedding: [0.09537440538406372, -0.026791611686348915, -0.07760915905237198, ...]\n",
            "\n",
            "Message: Find the cheapest indoor parking within 500 meters of my destination.\n",
            "Embedding size: 512\n",
            "Embedding: [0.03883657604455948, 0.06337009370326996, -0.005243263673037291, ...]\n",
            "\n",
            "Message: Okay, can you find me a supermarket on my route that has a charging station?\n",
            "Embedding size: 512\n",
            "Embedding: [0.014376592822372913, -0.05717989057302475, 0.024920351803302765, ...]\n",
            "\n",
            "Message: Find parking near destination that accepts credit cards and has a valet service.\n",
            "Embedding size: 512\n",
            "Embedding: [0.030574841424822807, -0.00577931385487318, 0.030697403475642204, ...]\n",
            "\n",
            "Message: Navigate to San Francisco Museum of Modern Art.\n",
            "Embedding size: 512\n",
            "Embedding: [0.027134902775287628, -0.010075404308736324, -0.0532539039850235, ...]\n",
            "\n",
            "Message: What's my ETA to destination?\n",
            "Embedding size: 512\n",
            "Embedding: [0.07457554340362549, 0.003240124089643359, -0.03426318243145943, ...]\n",
            "\n",
            "Message: Show me alternative routes.\n",
            "Embedding size: 512\n",
            "Embedding: [0.06479471176862717, -0.03071426786482334, -0.051688600331544876, ...]\n",
            "\n",
            "Message: Reroute using I-580 East.\n",
            "Embedding size: 512\n",
            "Embedding: [0.07350993156433105, -0.0003813255752902478, -0.03131583333015442, ...]\n",
            "\n",
            "Message: Show route overview.\n",
            "Embedding size: 512\n",
            "Embedding: [0.05674076825380325, -0.0077915797010064125, -0.03142654523253441, ...]\n",
            "\n",
            "Message: Drive to Downtown Berkeley.\n",
            "Embedding size: 512\n",
            "Embedding: [0.05065593123435974, 0.031679101288318634, 0.004378451965749264, ...]\n",
            "\n",
            "Message: What's my drive range?\n",
            "Embedding size: 512\n",
            "Embedding: [0.05642839893698692, 0.09078410267829895, -0.0037272125482559204, ...]\n",
            "\n",
            "Message: Can I make tomorrow's 10am meeting without recharging?\n",
            "Embedding size: 512\n",
            "Embedding: [0.020251302048563957, -0.09235230088233948, 0.03127354383468628, ...]\n",
            "\n",
            "Message: What's traffic like on the Bay Bridge?\n",
            "Embedding size: 512\n",
            "Embedding: [0.04259370267391205, -0.029599538072943687, -0.001719944179058075, ...]\n",
            "\n",
            "Message: Are there any speed cameras on my route?\n",
            "Embedding size: 512\n",
            "Embedding: [0.032204966992139816, 0.010780662298202515, -0.01248216163367033, ...]\n",
            "\n",
            "Message: Will it rain tomorrow in Oakland?\n",
            "Embedding size: 512\n",
            "Embedding: [0.019932642579078674, 0.057807568460702896, -0.029217004776000977, ...]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4aSYPrPCKMKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute a representation for each message, showing various lengths supported.\n",
        "test_message = [\"Where is a gas station with a restroom nearby?\",\n",
        "               \"Find routes to New York University.\"]\n",
        "test_labels = [3, 8]\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  #임베딩 시작\n",
        "  test_message_embeddings = session.run(embed(test_message))\n",
        "  #test_message_embedding = test_message_embeddings[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fJYjYfRXcjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "07eff75c-da1f-4ee5-be81-4ef8a51d04a9"
      },
      "cell_type": "code",
      "source": [
        "for test_message_embedding, test_label in zip(test_message_embeddings, test_labels):\n",
        "  minimum = 100\n",
        "  minimum_index = 0\n",
        "  for i, message_embedding in enumerate(message_embeddings):\n",
        "    error = rmse(np.array(message_embedding), np.array(test_message_embedding))\n",
        "    if minimum > error:\n",
        "      minimum = error\n",
        "      minimum_index = i\n",
        "\n",
        "  print(\"Minimum RMSE value: {}\".format(minimum))\n",
        "  print(\"Most similar script: {}\".format(scripts[minimum_index]))\n",
        "  print(\"Estimation: {}\".format(minimum_index))\n",
        "  print(\"Answer: {}\\n\".format(test_label))\n",
        "  #프로파일 데이터의 명사들 변환 필요\n",
        "  #테스트 데이터의 명사들 변환 필요\n",
        "  #다른 문장들도 테스트 해볼 것."
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum RMSE value: 0.037473857402801514\n",
            "Most similar script: [SEARCH ONE FROM:SUPERMARKET WHERE:ONROUTE WITH:CHARGINGSTATION]\n",
            "Estimation: 6\n",
            "Answer: 3\n",
            "\n",
            "Minimum RMSE value: 0.037789326161146164\n",
            "Most similar script: [MODE GUIDANCE WITH:[ROUTE TO:[SEARCH KEYWORD:”Downtown Berkeley”]]]\n",
            "Estimation: 13\n",
            "Answer: 8\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n-YvXHJVrXMg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}