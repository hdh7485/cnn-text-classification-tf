{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NavScript180609",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/hdh7485/cnn-text-classification-tf/blob/master/NavScript.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "RUymE2l9GZfO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "JMyTNwSJGGWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_u-x-nI5EOXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "acbdedd1-84b6-4f06-d952-5cc608ce4142"
      },
      "cell_type": "code",
      "source": [
        "!ps ax|grep python"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   89 ?        Sl     0:01 /usr/bin/python2 /usr/local/bin/jupyter-notebook -y --no-browser --log-level=DEBUG --debug --NotebookApp.allow_origin=\"*\" --NotebookApp.log_format=\"%(message)s\" --NotebookApp.token= --Session.key=\"\" --Session.keyfile=\"\" --ContentsManager.untitled_directory=\"Untitled Folder\" --ContentsManager.untitled_file=\"Untitled File\" --ContentsManager.untitled_notebook=\"Untitled Notebook\" --NotebookNotary.algorithm=\"sha1\" --KernelManager.autorestart=True --MultiKernelManager.default_kernel_name=\"python2\" --ip=\"127.0.0.1\" --port=9000 --port-retries=0 --notebook-dir=\"/content\" --NotebookNotary.algorithm=sha256 --NotebookNotary.secret_file=/content/datalab/.config/notary_secret --NotebookApp.base_url=/tun/m/gpu-067d6fa4-e306-4377-9f4b-c07c92dcd2c6/\r\n",
            "   97 ?        Ssl    1:08 /usr/bin/python3 -m ipykernel_launcher -f /content/.local/share/jupyter/runtime/kernel-f4d2fe6f-149d-4e4f-b66d-a11eb4ac6ca7.json\r\n",
            "  648 pts/0    Ss+    0:01 /bin/sh -c ps ax|grep python\r\n",
            "  650 pts/0    S+     0:00 grep python\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "__UZ7CnAedEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "3597edc5-1d12-4dde-8b49-2b3d93488f5b"
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwnnSLU9eTxe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5c40a966-79e3-4f13-cca5-9be33b108d49"
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 11.3 GB  I Proc size: 1.8 GB\n",
            "GPU RAM Free: 548MB | Used: 10891MB | Util  95% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "co7MV6sX7Xto",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Universal Sentence Encoder\n",
        "\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td></table>\n"
      ]
    },
    {
      "metadata": {
        "id": "eAVQGidpL8v5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
        "\n",
        "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
      ]
    },
    {
      "metadata": {
        "id": "pOTzp8O36CyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "\n",
        "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
      ]
    },
    {
      "metadata": {
        "id": "lVjNK8shFKOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5f76d4ad-3ab1-40da-b7db-7412e0c0baf7"
      },
      "cell_type": "code",
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install seaborn"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.7.1)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "63Pd3nJnTl-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
      ]
    },
    {
      "metadata": {
        "id": "MSeY-MUQo2Ha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6j1I5msVLY3N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rmse(predictions, targets):\n",
        "  return np.sqrt(((predictions - targets)**2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwty8Z6mAkdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 미리 학습된 모듈의 url\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/1\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/1\", \"https://tfhub.dev/google/universal-sentence-encoder-large/1\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8F4LNGFqOiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)\n",
        "\n",
        "scripts = [\"[SEARCH FROM:WEATHERFORECAST WHERE:HERE WHEN:AFTERNOON]\",\n",
        "         \"[SEARCH FROM:TRAFFIC WHERE:ONROUTE]\",\n",
        "         \"[SEARCH FROM:TRAFFICCAMERA WHERE:[SEARCH GEOCODE WHERE:”US-101 and Bayshore Blvd”]]\",\n",
        "         \"[SEARCH FROM:GASSTATION WHERE:NEARBY WITH:RESTROOM]\",\n",
        "         \"[SEARCH ONE FROM:COFFEESHOP WHERE:ALONGROUTE]\",\n",
        "         \"[SEARCH ONE FROM:OFFROADPARKING WHERE:DESTINATION RANGE:500M WITH:[SORT PRICE ASC]]\",\n",
        "         \"[SEARCH ONE FROM:SUPERMARKET WHERE:ONROUTE WITH:CHARGINGSTATION]\",\n",
        "         \"[SEARCH ONE FROM:PARKING WITH:CREDITCARD WITH:VALETSERVICE]\"]\n",
        "\n",
        "# Compute a representation for each message, showing various lengths supported.\n",
        "messages = [\"What's the weather forecast for this afternoon?\",\n",
        "            \"What's the traffic like on my route?\",\n",
        "            \"Show me a Traffic Camera on US-101 and Bayshore Blvd.\",\n",
        "            \"Can you find me a gas station with restroom facilities nearby?\",\n",
        "            \"Find a coffee shop along route.\",\n",
        "            \"Find the cheapest indoor parking within 500 meters of my destination.\",\n",
        "            \"Okay, can you find me a supermarket on my route that has a charging station?\",\n",
        "            \"Find parking near destination that accepts credit cards and has a valet service.\"\n",
        "            ]\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  #임베딩 시작\n",
        "  message_embeddings = session.run(embed(messages))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pzff6G4YH4jY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "a9d9973a-08f3-41aa-9550-7a1532904071"
      },
      "cell_type": "code",
      "source": [
        "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "    print(\"Message: {}\".format(messages[i]))\n",
        "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
        "    message_embedding_snippet = \", \".join(\n",
        "        (str(x) for x in message_embedding[:3]))\n",
        "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message: What's the weather forecast for this afternoon?\n",
            "Embedding size: 512\n",
            "Embedding: [0.04351525008678436, 0.06211598217487335, -0.016318896785378456, ...]\n",
            "\n",
            "Message: What's the traffic like on my route?\n",
            "Embedding size: 512\n",
            "Embedding: [0.06461557745933533, 0.044308360666036606, 0.0400204062461853, ...]\n",
            "\n",
            "Message: Show me a Traffic Camera on US-101 and Bayshore Blvd.\n",
            "Embedding size: 512\n",
            "Embedding: [0.02503906562924385, -0.03478128835558891, 0.06629729270935059, ...]\n",
            "\n",
            "Message: Can you find me a gas station with restroom facilities nearby?\n",
            "Embedding size: 512\n",
            "Embedding: [0.025977516546845436, -0.01725350320339203, 0.015602072700858116, ...]\n",
            "\n",
            "Message: Find a coffee shop along route.\n",
            "Embedding size: 512\n",
            "Embedding: [0.030696842819452286, -0.04817262664437294, 0.028483519330620766, ...]\n",
            "\n",
            "Message: Find the cheapest indoor parking within 500 meters of my destination.\n",
            "Embedding size: 512\n",
            "Embedding: [0.03883657604455948, 0.06337009370326996, -0.005243263673037291, ...]\n",
            "\n",
            "Message: Okay, can you find me a supermarket on my route that has a charging station?\n",
            "Embedding size: 512\n",
            "Embedding: [0.014376592822372913, -0.05717989057302475, 0.024920351803302765, ...]\n",
            "\n",
            "Message: Find parking near destination that accepts credit cards and has a valet service.\n",
            "Embedding size: 512\n",
            "Embedding: [0.030574841424822807, -0.00577931385487318, 0.030697403475642204, ...]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4aSYPrPCKMKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute a representation for each message, showing various lengths supported.\n",
        "test_message = [\"Where is a gas station with a restroom nearby?\"]\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  #임베딩 시작\n",
        "  test_message_embeddings = session.run(embed(test_message))\n",
        "  test_message_embedding = test_message_embeddings[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fJYjYfRXcjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2414cc93-1671-412a-be0c-e95d8a28ba52"
      },
      "cell_type": "code",
      "source": [
        "minimum = 100\n",
        "minimum_index = 0\n",
        "for i, message_embedding in enumerate(message_embeddings):\n",
        "  error = rmse(np.array(message_embedding), np.array(test_message_embedding))\n",
        "  if minimum > error:\n",
        "    minimum = error\n",
        "    minimum_index = i\n",
        "    \n",
        "print(\"Minimum RMSE value: {}\".format(minimum))\n",
        "print(\"Minimum index: {}\".format(minimum_index))\n",
        "print(\"Most similar script: {}\".format(scripts[minimum_index]))\n",
        "#프로파일 데이터의 명사들 변환 필요\n",
        "#테스트 데이터의 명사들 변환 필요\n",
        "#다른 문장들도 테스트 해볼 것."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum RMSE value: 0.021709490567445755\n",
            "Minimum index: 3\n",
            "Most similar script: [SEARCH FROM:GASSTATION WHERE:NEARBY WITH:RESTROOM]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}